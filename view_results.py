#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import division

import os
import sys

# Hack so you don't have to put the library containing this  script in the PYTHONPATH.
sys.path = [os.path.abspath(os.path.join(__file__, '..', '..'))] + sys.path

import numpy as np
import argparse

import re
from texttable import Texttable

from os.path import join as pjoin

from iRBM.misc.utils import load_dict_from_json_file


def sort_nicely(col):
    """ Sort the given list in the way that humans expect.
    """
    convert = lambda text: int(text) if text.isdigit() else text
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key[col])]
    return alphanum_key

#
# Script part #
#
DESCRIPTION = 'Viewer for results generated by mlpython.'


def buildArgsParser():
    p = argparse.ArgumentParser(description=DESCRIPTION)

    # General parameters
    p.add_argument('results', metavar='FILE/DIR', nargs='+',
                   help='file or folder containing results (result.json).')
    p.add_argument('-s', '--sort', metavar='ID', type=int, nargs='+', default=[],
                   help="sort rows by column ID in ascending (+ID) or descending (-ID) order")

    p.add_argument('--only-header', action='store_true',
                   help='print only the header with column ID')

    p.add_argument('--out', help='save table in a CSV file.')

    return p


def main():
    parser = buildArgsParser()
    args = parser.parse_args()

    sort_by = args.sort

    results_files = []
    hyperparams_files = []
    status_files = []
    for f in args.results:
        exp_folder = f
        if os.path.isfile(f):
            exp_folder = os.path.dirname(f)

        result_file = pjoin(exp_folder, "result.json")
        hyperparams_file = pjoin(exp_folder, "hyperparams.json")
        status_file = pjoin(exp_folder, "status.json")

        if not os.path.isfile(result_file):
            parser.error('{0} is not a file!'.format(result_file))

        if not os.path.isfile(hyperparams_file):
            parser.error('{0} is not a file!'.format(hyperparams_file))

        if not os.path.isfile(status_file):
            parser.error('{0} is not a file!'.format(status_file))

        results_files.append(result_file)
        hyperparams_files.append(hyperparams_file)
        status_files.append(status_file)

    if len([no for no in sort_by if no == 0]) > 0:
        parser.error('Column ID are starting at 1!')

    # Retrieve headers from hyperparams
    headers_hyperparams = set()
    headers_results = set()
    headers_status = set()

    for hyperparams_file, status_file, results_file in zip(hyperparams_files, status_files, results_files):
        hyperparams = load_dict_from_json_file(hyperparams_file)
        results = load_dict_from_json_file(results_file)
        status = load_dict_from_json_file(status_file)
        headers_hyperparams |= set(hyperparams.keys())
        headers_results |= set(results.keys())
        headers_status |= set(status.keys())

    headers_hyperparams = sorted(list(headers_hyperparams))
    headers_status = sorted(list(headers_status))
    # TODO: when generating result.json split 'trainset' scores in two key:
    #       'trainset' and 'trainset_std' (same goes for validset and testset).
    headers_results |= set(["trainset_std", "validset_std", "testset_std"])
    headers_results = sorted(list(headers_results))
    headers = headers_hyperparams + headers_status + headers_results

    # Build results table
    table = Texttable(max_width=0)
    table.set_deco(Texttable.HEADER)
    table.set_precision(8)
    table.set_cols_dtype(['a'] * len(headers))
    table.set_cols_align(['c'] * len(headers))

    # Headers
    table.header([str(i) + "\n" + h for i, h in enumerate(headers, start=1)])

    if args.only_header:
        print table.draw()
        return

    # Results
    for hyperparams_file, status_file, results_file in zip(hyperparams_files, status_files, results_files):
        hyperparams = load_dict_from_json_file(hyperparams_file)
        results = load_dict_from_json_file(results_file)
        status = load_dict_from_json_file(status_file)

        # Build results table row (hyperparams columns)
        row = []
        for h in headers_hyperparams:
            value = hyperparams.get(h, '')
            row.append(value)

        for h in headers_status:
            value = status.get(h, '')
            row.append(value)

        for h in headers_results:
            if h in ["trainset", "validset", "testset"]:
                value = results.get(h, '')[0]
            elif h in ["trainset_std", "validset_std", "testset_std"]:
                value = results.get(h[:-4], '')[1]
            else:
                value = results.get(h, '')
            row.append(value)

        table.add_row(row)

    # Sort
    for col in reversed(sort_by):
        table._rows = sorted(table._rows, key=sort_nicely(abs(col) - 1), reverse=col < 0)

    if args.out is not None:
        import csv

        results = []
        results.append(headers)
        results.extend(table._rows)

        with open(args.out, 'wb') as csvfile:
            w = csv.writer(csvfile)
            w.writerows(results)

    else:
        print table.draw()


if __name__ == "__main__":
    main()
